ğŸŒ¸ Iris Dataset â€” Hello World de Machine Learning
Este repositÃ³rio apresenta um exercÃ­cio introdutÃ³rio de Machine Learning supervisionado, utilizando o clÃ¡ssico dataset Iris.
O objetivo Ã© entender conceitos fundamentais, mais do que â€œotimizar modelosâ€.
Pense neste projeto como o Hello World do ML: simples, didÃ¡tico e conceitualmente completo.

ğŸŒ¼ O que Ã© o dataset Iris?
O dataset Iris Ã© um conjunto de dados clÃ¡ssico da estatÃ­stica e do Machine Learning, criado por Ronald Fisher (1936).
Ele contÃ©m 150 amostras de flores do gÃªnero Iris, divididas em trÃªs espÃ©cies:
Setosa
Versicolor
Virginica
Cada flor foi medida fisicamente em laboratÃ³rio.

ğŸŒ¿ SÃ©pala e PÃ©tala â€” o que sÃ£o?
Cada flor possui duas estruturas principais:
SÃ©pala â†’ parte externa da flor (proteÃ§Ã£o)
PÃ©tala â†’ parte interna, geralmente colorida
Para cada flor, foram feitas quatro mediÃ§Ãµes:
Estrutura
Medida
SÃ©pala
Comprimento
SÃ©pala
Largura
PÃ©tala
Comprimento
PÃ©tala
Largura


ğŸ“ RepresentaÃ§Ã£o matemÃ¡tica dos dados
Os dados nÃ£o sÃ£o â€œfloresâ€ para o algoritmo.
Eles sÃ£o representados como vetores numÃ©ricos.
Forma do dataset
150 flores
Cada flor â†’ vetor em â„â´
Dataset completo â†’ matriz 150 Ã— 4
X âˆˆ â„^(150Ã—4)

Visualmente:
X = [
  [sepal_len, sepal_wid, petal_len, petal_wid],  â† flor 1
  [sepal_len, sepal_wid, petal_len, petal_wid],  â† flor 2
  ...
  [sepal_len, sepal_wid, petal_len, petal_wid]   â† flor 150
]

ğŸ‘‰ Classificar flores = classificar vetores em um espaÃ§o multidimensional

ğŸ¯ Objetivo do exercÃ­cio
Construir um pipeline bÃ¡sico de ML supervisionado, contendo:
SeparaÃ§Ã£o treino / teste
Treinamento de modelos
PrediÃ§Ã£o
AvaliaÃ§Ã£o por acurÃ¡cia e matriz de confusÃ£o
ComparaÃ§Ã£o entre algoritmos

ğŸ”€ SeparaÃ§Ã£o Treino / Teste
Utilizamos:
80% para treino
20% para teste
random_state = 42 para reprodutibilidade
ğŸ“Œ O modelo aprende apenas com o treino
ğŸ“Œ O teste funciona como uma â€œprova que ele nunca viuâ€

ğŸ¤– Algoritmos utilizados
Este projeto testa trÃªs algoritmos clÃ¡ssicos de classificaÃ§Ã£o:
1ï¸âƒ£ k-Nearest Neighbors (kNN)
Classifica pela distÃ¢ncia entre vetores
SensÃ­vel Ã  escolha das features
Muito intuitivo para fins didÃ¡ticos
2ï¸âƒ£ Support Vector Machine (SVM)
Busca uma fronteira Ã³tima de separaÃ§Ã£o
Funciona bem mesmo com menos informaÃ§Ã£o
Forte em espaÃ§os de baixa dimensÃ£o
3ï¸âƒ£ Random Forest
Conjunto de Ã¡rvores de decisÃ£o
Mais robusto, menos sensÃ­vel a ruÃ­do
Serve como bom â€œbaseline modernoâ€

ğŸ§ª Experimento didÃ¡tico central
Experimento 1 â€” Todas as features (â„â´)
Usando:
sÃ©palas + pÃ©talas
ğŸ“Œ Resultado esperado:
AcurÃ¡cia prÃ³xima de 1.0
Matrizes de confusÃ£o quase perfeitas
ğŸ‘‰ Mostra que o problema Ã© facilmente separÃ¡vel quando hÃ¡ informaÃ§Ã£o suficiente.

Experimento 2 â€” Apenas sÃ©palas (â„Â²)
Usando:
comprimento e largura da sÃ©pala
ğŸ“Œ Resultado observado:
kNN â‰ˆ 0.70
SVM â‰ˆ 0.90
Random Forest â‰ˆ 0.76
ğŸ‘‰ Aqui fica claro que:
Reduzir features reduz informaÃ§Ã£o
Algoritmos reagem de forma diferente Ã  mesma limitaÃ§Ã£o
Este Ã© o aprendizado mais importante do exercÃ­cio.

ğŸ“Š Matriz de ConfusÃ£o â€” por que usamos?
A matriz de confusÃ£o mostra:
acertos
erros
quais classes sÃ£o confundidas
Os valores na diagonal principal representam:
classificaÃ§Ãµes corretas
Fora da diagonal:
erros de classificaÃ§Ã£o entre espÃ©cies
ğŸ‘‰ Ela explica o tipo de erro, nÃ£o sÃ³ â€œquanto errouâ€.

ğŸ§  Por que isso Ã© o â€œHello World do MLâ€?
Porque neste exercÃ­cio vocÃª aprende:
o que sÃ£o features
o que Ã© label
o que Ã© vetor
o que Ã© treino vs teste
como avaliar um modelo
por que dados importam tanto quanto algoritmos
Sem:
deep learning
tuning excessivo
abstraÃ§Ãµes mÃ¡gicas

ğŸš€ ConclusÃ£o
Machine Learning comeÃ§a com geometria, nÃ£o com IA.
Este projeto mostra que ML Ã©, antes de tudo:
matemÃ¡tica aplicada
representaÃ§Ã£o de dados
tomada de decisÃ£o baseada em exemplos
Um verdadeiro Hello World, feito do jeito certo.